{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "queRvxIbJZZS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9mM5vFeJSwI"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/synthetic_sensor_data_with_rul.csv')\n",
        "data = data.drop(['timestamp'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8I6BEB1KxB0",
        "outputId": "cb93faa8-c5c2-4f8c-da0d-e5889141a04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0825\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - loss: 0.0841 - val_loss: 0.0824\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: 0.0826\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - loss: 0.0839 - val_loss: 0.0826\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12ms/step - loss: 0.0836 - val_loss: 0.0827\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - loss: 0.0837 - val_loss: 0.0826\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0839 - val_loss: 0.0824\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0824\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0837 - val_loss: 0.0824\n"
          ]
        }
      ],
      "source": [
        "X = data.drop(['rul'], axis=1).values\n",
        "y = data['rul'].values.reshape(-1, 1)\n",
        "\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X = feature_scaler.fit_transform(X)\n",
        "y = target_scaler.fit_transform(y)\n",
        "\n",
        "def create_sequences(data, target, seq_length=10):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i + seq_length])\n",
        "        y_seq.append(target[i + seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "X_seq, y_seq = create_sequences(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "i5RnY4Vs-3yd",
        "outputId": "2f4b9aeb-9d9b-445b-9284-7659c707feb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0823\n",
            "\n",
            "\n",
            "Test Loss: 0.08244835585355759\n",
            "\n",
            "\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"\\n\")\n",
        "print(f'Test Loss: {loss}')\n",
        "print(\"\\n\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_rescaled = target_scaler.inverse_transform(y_pred)\n",
        "y_test_rescaled = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test_rescaled, label='True RUL')\n",
        "plt.plot(y_pred_rescaled, label='Predicted RUL')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Jt20AGRPIw-v",
        "outputId": "90e576f5-829e-4e64-fe83-7160bdd80fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0823\n",
            "Test Loss (MSE): 0.08244835585355759\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "ename": "NotFittedError",
          "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-742c6ec73c2a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_pred_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_test_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "loss = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test Loss (MSE): {loss}')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_rescaled = target_scaler.inverse_transform(y_pred)\n",
        "y_test_rescaled = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
        "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_rescaled, y_pred_rescaled)\n",
        "\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'R-squared (R²): {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOK2hiCJUz6q",
        "outputId": "d515d07a-612f-4d6c-acfe-6a0b3cd58d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "GRzIgT51TYlv",
        "outputId": "41bb65bb-f0a0-4214-d2a0-24a2d3b84f76"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: '2022-03-13 23:04:27.018491'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ede02418f8d1>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtarget_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2022-03-13 23:04:27.018491'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from keras_tuner import RandomSearch\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv(\"synthetic_sensor_data_with_rul.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(['rul'], axis=1).values\n",
        "y = data['rul'].values.reshape(-1, 1)\n",
        "\n",
        "# Scale features and target\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X = feature_scaler.fit_transform(X)\n",
        "y = target_scaler.fit_transform(y)\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(data, target, seq_length=10):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i + seq_length])\n",
        "        y_seq.append(target[i + seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 10\n",
        "X_seq, y_seq = create_sequences(X, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model-building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First LSTM layer\n",
        "    model.add(\n",
        "        LSTM(\n",
        "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
        "            activation='relu',\n",
        "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "            return_sequences=True\n",
        "        )\n",
        "    )\n",
        "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Second LSTM layer\n",
        "    model.add(\n",
        "        LSTM(\n",
        "            units=hp.Int('units_2', min_value=16, max_value=128, step=16),\n",
        "            activation='relu',\n",
        "            return_sequences=False\n",
        "        )\n",
        "    )\n",
        "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Dense output layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "        ),\n",
        "        loss='mse'\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize Keras Tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning_dir',\n",
        "    project_name='rul_tuning'\n",
        ")\n",
        "\n",
        "# Run the tuner\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32, verbose=1)\n",
        "\n",
        "# Get the best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best Hyperparameters:\")\n",
        "print(f\" - Units Layer 1: {best_hps.get('units_1')}\")\n",
        "print(f\" - Dropout Layer 1: {best_hps.get('dropout_1')}\")\n",
        "print(f\" - Units Layer 2: {best_hps.get('units_2')}\")\n",
        "print(f\" - Dropout Layer 2: {best_hps.get('dropout_2')}\")\n",
        "print(f\" - Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# Train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,  # You can increase this for better performance\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_original = target_scaler.inverse_transform(y_pred)\n",
        "y_test_original = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "# Calculate R² Score\n",
        "r2 = r2_score(y_test_original, y_pred_original)\n",
        "print(f\"R² Score: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtJ5SDXPVajt",
        "outputId": "30721569-ecd1-4c6a-ceed-589bcdc016be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 21m 12s]\n",
            "val_loss: 4.385790089145303e-05\n",
            "\n",
            "Best val_loss So Far: 1.4049067431187723e-05\n",
            "Total elapsed time: 01h 26m 29s\n",
            "\n",
            "Search: Running Trial #6\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "96                |192               |units_1\n",
            "0.1               |0.1               |dropout_1\n",
            "32                |96                |units_2\n",
            "0.5               |0.3               |dropout_2\n",
            "0.0005382         |0.0012226         |learning_rate\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - loss: 0.0252 - val_loss: 0.0013\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - loss: 0.0058 - val_loss: 3.4113e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - loss: 0.0057 - val_loss: 6.2998e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - loss: 0.0057 - val_loss: 3.1507e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - loss: 0.0056 - val_loss: 3.0416e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m 193/2500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 11ms/step - loss: 0.0058"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from keras_tuner import RandomSearch\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load data\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Check for non-numeric columns\n",
        "    print(data.dtypes)\n",
        "\n",
        "    # Convert timestamp column (if exists) to Unix timestamp or drop it\n",
        "    if 'timestamp' in data.columns:  # Replace 'timestamp' with actual column name\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp']).astype(np.int64) // 10**9  # Unix timestamp\n",
        "\n",
        "    # If there are categorical columns, you can encode them or drop them\n",
        "    data = pd.get_dummies(data, drop_first=True)  # One-hot encode categorical columns (if any)\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop(['rul'], axis=1).values\n",
        "    y = data['rul'].values.reshape(-1, 1)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Normalization pipeline\n",
        "def normalize_data(X, y):\n",
        "    feature_scaler = MinMaxScaler()\n",
        "    target_scaler = MinMaxScaler()\n",
        "    X_norm = feature_scaler.fit_transform(X)\n",
        "    y_norm = target_scaler.fit_transform(y)\n",
        "    return X_norm, y_norm, feature_scaler, target_scaler\n",
        "\n",
        "# Standardization pipeline\n",
        "def standardize_data(X, y):\n",
        "    feature_scaler = StandardScaler()\n",
        "    target_scaler = StandardScaler()\n",
        "    X_std = feature_scaler.fit_transform(X)\n",
        "    y_std = target_scaler.fit_transform(y)\n",
        "    return X_std, y_std, feature_scaler, target_scaler\n",
        "\n",
        "# Create sequences for LSTM\n",
        "def create_sequences(data, target, seq_length=10):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i + seq_length])\n",
        "        y_seq.append(target[i + seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# Model building function\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First LSTM layer\n",
        "    model.add(\n",
        "        LSTM(\n",
        "            units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
        "            activation='relu',\n",
        "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "            return_sequences=True\n",
        "        )\n",
        "    )\n",
        "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Second LSTM layer\n",
        "    model.add(\n",
        "        LSTM(\n",
        "            units=hp.Int('units_2', min_value=16, max_value=128, step=16),\n",
        "            activation='relu',\n",
        "            return_sequences=False\n",
        "        )\n",
        "    )\n",
        "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Dense output layer\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "        ),\n",
        "        loss='mse'\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Train and evaluate model\n",
        "def train_and_evaluate(X, y, scaler_name):\n",
        "    # Create sequences\n",
        "    seq_length = 10\n",
        "    X_seq, y_seq = create_sequences(X, y)\n",
        "\n",
        "    # Train-test split\n",
        "    global X_train, X_test, y_train, y_test  # Used in the build_model function\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize Keras Tuner\n",
        "    tuner = RandomSearch(\n",
        "        build_model,\n",
        "        objective='val_loss',\n",
        "        max_trials=10,\n",
        "        executions_per_trial=1,\n",
        "        directory='tuning_dir',\n",
        "        project_name=f'rul_tuning_{scaler_name}'\n",
        "    )\n",
        "\n",
        "    # Run the tuner\n",
        "    tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32, verbose=1)\n",
        "\n",
        "    # Get the best model\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    print(f\"Best Hyperparameters for {scaler_name}:\")\n",
        "    print(f\" - Units Layer 1: {best_hps.get('units_1')}\")\n",
        "    print(f\" - Dropout Layer 1: {best_hps.get('dropout_1')}\")\n",
        "    print(f\" - Units Layer 2: {best_hps.get('units_2')}\")\n",
        "    print(f\" - Dropout Layer 2: {best_hps.get('dropout_2')}\")\n",
        "    print(f\" - Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "    # Train the best model\n",
        "    best_model = tuner.hypermodel.build(best_hps)\n",
        "    history = best_model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=50,  # Increase for better performance\n",
        "        validation_data=(X_test, y_test),\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_pred_original = target_scaler.inverse_transform(y_pred)\n",
        "    y_test_original = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "    # Calculate R² Score\n",
        "    r2 = r2_score(y_test_original, y_pred_original)\n",
        "    print(f\"R² Score with {scaler_name}: {r2}\")\n",
        "    return r2\n",
        "\n",
        "# Main pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    X, y = load_data(\"synthetic_sensor_data_with_rul.csv\")\n",
        "\n",
        "    # Normalize data\n",
        "    X_norm, y_norm, norm_feature_scaler, norm_target_scaler = normalize_data(X, y)\n",
        "    print(\"Running with Normalization...\")\n",
        "    r2_normalization = train_and_evaluate(X_norm, y_norm, \"Normalization\")\n",
        "\n",
        "    # Standardize data\n",
        "    X_std, y_std, std_feature_scaler, std_target_scaler = standardize_data(X, y)\n",
        "    print(\"Running with Standardization...\")\n",
        "    r2_standardization = train_and_evaluate(X_std, y_std, \"Standardization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHvElGdebQmG",
        "outputId": "9ec5a1ed-c210-467d-d236-5ef238f30b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qUYUbPItch0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/synthetic_sensor_data_with_rul.csv\")\n",
        "data.head()\n",
        "data = data.drop(['timestamp'], axis=1)"
      ],
      "metadata": {
        "id": "cV0SjoLBcgtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9n9RM3MWWcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab64622-d576-4f66-f197-5d81f3eef7bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.74835708e+01 1.70611892e+03 1.51236814e+00]\n",
            " [4.43086785e+01 1.26892905e+03 1.18115434e+00]]\n",
            "[[138005.34905286]\n",
            " [138004.34905286]]\n",
            "[[0.55477821 0.60480552 0.69217561]\n",
            " [0.48378876 0.36018703 0.50035114]]\n",
            "[[1.     ]\n",
            " [0.99999]]\n"
          ]
        }
      ],
      "source": [
        "X = data.drop(['rul'], axis=1).values\n",
        "y = data['rul'].values.reshape(-1, 1)\n",
        "\n",
        "print(X[:2])\n",
        "print(y[:2])\n",
        "\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "X = feature_scaler.fit_transform(X)\n",
        "y = target_scaler.fit_transform(y)\n",
        "\n",
        "print(X[:2])\n",
        "print(y[:2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, target, seq_length=10):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i + seq_length])\n",
        "        y_seq.append(target[i + seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 30\n",
        "X_seq, y_seq = create_sequences(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "parameter_configs = [{\"units_1\": 128, \"dropout_1\": 0.2, \"units_2\": 64, \"dropout_2\": 0.2, \"learning_rate\": 1e-3},{\"units_1\": 64, \"dropout_1\": 0.3, \"units_2\": 32, \"dropout_2\": 0.3, \"learning_rate\": 5e-4},{\"units_1\": 256, \"dropout_1\": 0.1, \"units_2\": 128, \"dropout_2\": 0.1, \"learning_rate\": 1e-4},]\n",
        "results = []\n",
        "\n",
        "for idx, config in enumerate(parameter_configs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=config[\"units_1\"],activation=\"relu\",input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True,))\n",
        "    model.add(Dropout(config[\"dropout_1\"]))\n",
        "    model.add(LSTM(units=config[\"units_2\"],activation=\"relu\",return_sequences=False,))\n",
        "    model.add(Dropout(config[\"dropout_2\"]))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"]),loss=\"mse\")\n",
        "\n",
        "    print(f\"Training model {idx + 1} with parameters: {config}\")\n",
        "    history = model.fit(X_train,y_train,epochs=30, validation_data=(X_test, y_test),batch_size=32,verbose=1,)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_original = target_scaler.inverse_transform(y_pred)\n",
        "    y_test_original = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "    r2 = r2_score(y_test_original, y_pred_original)\n",
        "    results.append({\"config\": config, \"r2\": r2, \"model\": model, \"history\": history})\n",
        "    print(f\"Model {idx + 1} R² Score: {r2}\")\n",
        "\n",
        "best_result = max(results, key=lambda x: x[\"r2\"])\n",
        "print(\"Best configuration:\")\n",
        "print(best_result[\"config\"])\n",
        "print(f\"Best R² Score: {best_result['r2']}\")\n",
        "\n",
        "y_pred = best_result[\"model\"].predict(X_test)\n",
        "y_pred_original = target_scaler.inverse_transform(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "odF_lChvbDIe",
        "outputId": "40be222e-3935-4c7e-f4c3-84c606e947b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 1 with parameters: {'units_1': 128, 'dropout_1': 0.2, 'units_2': 64, 'dropout_2': 0.2, 'learning_rate': 0.001}\n",
            "Epoch 1/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 23ms/step - loss: 0.0921 - val_loss: 0.0831\n",
            "Epoch 2/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 23ms/step - loss: 0.0842 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 23ms/step - loss: 0.0839 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - loss: 0.0835 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - loss: 0.0835 - val_loss: 0.0824\n",
            "Epoch 9/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 23ms/step - loss: 0.0838 - val_loss: 0.0824\n",
            "Epoch 10/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - loss: 0.0838 - val_loss: 0.0824\n",
            "Epoch 11/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 23ms/step - loss: 0.0840 - val_loss: 0.0824\n",
            "Epoch 12/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 23ms/step - loss: 0.0833 - val_loss: 0.0824\n",
            "Epoch 13/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 24ms/step - loss: 0.0838 - val_loss: 0.0825\n",
            "Epoch 14/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 15/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 16/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 17/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 18/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 24ms/step - loss: 0.0838 - val_loss: 0.0824\n",
            "Epoch 19/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 20/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 23ms/step - loss: 0.0833 - val_loss: 0.0824\n",
            "Epoch 21/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 22/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 24ms/step - loss: 0.0834 - val_loss: 0.0826\n",
            "Epoch 23/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 23ms/step - loss: 0.0835 - val_loss: 0.0824\n",
            "Epoch 24/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0825\n",
            "Epoch 25/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 24ms/step - loss: 0.0840 - val_loss: 0.0824\n",
            "Epoch 26/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 27/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 28/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - loss: 0.0829 - val_loss: 0.0824\n",
            "Epoch 29/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 24ms/step - loss: 0.0833 - val_loss: 0.0825\n",
            "Epoch 30/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - loss: 0.0835 - val_loss: 0.0824\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step\n",
            "Model 1 R² Score: -0.0002971638609352567\n",
            "Training model 2 with parameters: {'units_1': 64, 'dropout_1': 0.3, 'units_2': 32, 'dropout_2': 0.3, 'learning_rate': 0.0005}\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 0.0998 - val_loss: 0.0826\n",
            "Epoch 2/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0853 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0847 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0835 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0841 - val_loss: 0.0824\n",
            "Epoch 9/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0824\n",
            "Epoch 10/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0837 - val_loss: 0.0825\n",
            "Epoch 11/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0839 - val_loss: 0.0824\n",
            "Epoch 12/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0832 - val_loss: 0.0825\n",
            "Epoch 13/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - loss: 0.0832 - val_loss: 0.0824\n",
            "Epoch 14/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 15/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0839 - val_loss: 0.0824\n",
            "Epoch 16/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 17/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 18/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 19/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - loss: 0.0837 - val_loss: 0.0824\n",
            "Epoch 20/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0836 - val_loss: 0.0824\n",
            "Epoch 21/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12ms/step - loss: 0.0835 - val_loss: 0.0823\n",
            "Epoch 22/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - loss: 0.0833 - val_loss: 0.0823\n",
            "Epoch 23/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 13ms/step - loss: 0.0836 - val_loss: 0.0822\n",
            "Epoch 24/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0834 - val_loss: 0.0823\n",
            "Epoch 25/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12ms/step - loss: 0.0839 - val_loss: 0.0822\n",
            "Epoch 26/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - loss: 0.0831 - val_loss: 0.0822\n",
            "Epoch 27/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 0.0836 - val_loss: 0.0822\n",
            "Epoch 28/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 0.0836 - val_loss: 0.0822\n",
            "Epoch 29/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0835 - val_loss: 0.0822\n",
            "Epoch 30/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0834 - val_loss: 0.0822\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "Model 2 R² Score: 0.0023033813859512087\n",
            "Training model 3 with parameters: {'units_1': 256, 'dropout_1': 0.1, 'units_2': 128, 'dropout_2': 0.1, 'learning_rate': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 56ms/step - loss: 0.0975 - val_loss: 0.0829\n",
            "Epoch 2/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 55ms/step - loss: 0.0847 - val_loss: 0.0826\n",
            "Epoch 3/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 55ms/step - loss: 0.0843 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 55ms/step - loss: 0.0845 - val_loss: 0.0833\n",
            "Epoch 5/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 55ms/step - loss: 0.0845 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 55ms/step - loss: 0.0842 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m 119/2500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 49ms/step - loss: 0.0842"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-cb59746dadce>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training model {idx + 1} with parameters: {config}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0my_pred_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test_original, label=\"Actual\", alpha=0.7)\n",
        "plt.plot(y_pred_original, label=\"Predicted\", alpha=0.7)\n",
        "plt.title(\"Actual vs Predicted\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"RUL\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(best_result[\"history\"].history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(best_result[\"history\"].history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eb6RpyHgc1pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-y2AKZZutqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRnibuYm2ss7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}